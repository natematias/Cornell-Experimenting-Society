{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Valid Tests and Packages from the Upworthy Archive\n",
    "## Example: Getting the Effect on Clickthrough Rates of Including a Notable Person's Name in Headlines\n",
    "*March 2020* - Marianne Aubin Le Quere \n",
    "\n",
    "This example code takes you through everything you need to get the minimum and maximum effect size of any property you wish in the Upworthy dataset. As an example, we look here at what the effect is on clickthrough rates of including a Notable Person's name in an Upworthy headline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import codecs, os\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import pprint\n",
    "import upworthy_methods as up\n",
    "\n",
    "## Set random seed from Brooklyn Integers\n",
    "## https://www.brooklynintegers.com/int/1713001553/\n",
    "random.seed(1713001553)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Load the Upworthy data\n",
    "The goal of this section is to load the exploratory dataset into a form that we can work with effectively. Here, the data structure we chose to work with is a [python dictionary](https://docs.python.org/3/tutorial/datastructures.html).\n",
    "\n",
    "We create two dictionaries:\n",
    "   * `tests`: This dictionary contains all the packages that are associated with each other. By saving a list of `package_ids` that are contained within a single test, we make it very easy to compare packages that belong to a single test.\n",
    "   * `packages`: This dictionary contains all the individual information for a single package. This includes information such as the headline, the lede, the url slug, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should rename these variables to the directory where your exploratory data file lives\n",
    "# from your terminal, you can type `pwd` on unix or `cd` on windows to know what your\n",
    "# current directory is\n",
    "data_dir = \"/Users/nathan/Documents/github/Upworthy-Research-Archive/create-research-samples/output/\"\n",
    "filename = \"upworthy-archive-exploratory-packages-03.12.2020.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22666 total package items created.\n",
      "4873 total test items created.\n"
     ]
    }
   ],
   "source": [
    "# this is all the information that will be associated with tests\n",
    "def test_object():\n",
    "    return {\"id\": None, \"headlines\":[], \"package_ids\":[]}\n",
    "\n",
    "# this is all the information that will be associated with packages\n",
    "def package_object():\n",
    "    return {\"headline\": None,\n",
    "            \"test_id\": None,\n",
    "            \"package_id\": None,\n",
    "            \"excerpt\": None,\n",
    "            \"lede\": None,\n",
    "            \"eyecatcher_id\": None,\n",
    "            \"share_text\": None,\n",
    "            \"square\": None,\n",
    "            \"created_at\": None,\n",
    "            \"updated_at\": None,\n",
    "            \"slug\": None,\n",
    "            \"impressions\": None,\n",
    "            \"clicks\": None,\n",
    "            \"significance\": None,\n",
    "            \"first_place\": None,\n",
    "            \"winner\": None,\n",
    "            \"test_week\": None\n",
    "            }\n",
    "\n",
    "#Note: This does not currently work. Need Nathan to take a look.\n",
    "#I think the date format is somehow different to the OG data?\n",
    "def apply_date(date_raw):\n",
    "    #parser.parse(date_raw)\n",
    "    return date_raw\n",
    "\n",
    "def load_columns(convert_method, list_of_keys, package_dict):\n",
    "    for key in list_of_keys:\n",
    "        package_dict[key] = convert_method(row[key])\n",
    "    return package_dict\n",
    "\n",
    "tests = defaultdict(test_object)\n",
    "packages = defaultdict(package_object)\n",
    "\n",
    "# this code runs through or csv file with the exploratory Upworthy data\n",
    "# and loads it into our two dictionaries\n",
    "with codecs.open(os.path.join(data_dir, filename)) as f:\n",
    "    for row in csv.DictReader(f):\n",
    "                \n",
    "        package_id = row['']\n",
    "        \n",
    "        # load strings\n",
    "        packages[package_id] = load_columns(str, ['headline', 'excerpt','lede', 'slug',\n",
    "                    'share_text', 'eyecatcher_id', 'square'], packages[package_id])\n",
    "        # load numbers\n",
    "        packages[package_id] = load_columns(int, ['impressions', 'clicks'], packages[package_id])\n",
    "        packages[package_id] = load_columns(float, ['significance'], packages[package_id])\n",
    "        \n",
    "        # load dates\n",
    "        packages[package_id] = load_columns(apply_date, ['created_at', 'updated_at'], packages[package_id])\n",
    "        packages[package_id] = load_columns(apply_date, ['test_week'], packages[package_id])\n",
    "        \n",
    "        # load booleans\n",
    "        packages[package_id] = load_columns(bool, ['first_place', 'winner'], packages[package_id])\n",
    "\n",
    "        packages[package_id]['test_id'] = row['clickability_test_id']\n",
    "        packages[package_id]['package_id'] = package_id\n",
    "        \n",
    "        test_id = packages[package_id]['test_id']\n",
    "        tests[test_id]['id'] = test_id\n",
    "        tests[test_id]['headlines'].append(packages[package_id]['headline'])\n",
    "        tests[test_id]['package_ids'].append(packages[package_id]['package_id'])\n",
    "        \n",
    "print(\"{0} total package items created.\".format(len(packages)))\n",
    "print(\"{0} total test items created.\".format(len(tests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prove to ourselves that this worked, we will print a random package and test just to allow ourselves to see what it looks like. You can use the below printing functions as you wish to see what your dictionary looks like at any point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_random_dictionary_item(dictionary, dictionary_name):\n",
    "    pp = pprint.PrettyPrinter(indent=1)\n",
    "    random_key, random_value = random.choice(list(dictionary.items()))\n",
    "    print(\"****** Printing {0} Value at Random *******\".format(dictionary_name))\n",
    "    pp.pprint(random_value)\n",
    "    \n",
    "def print_dictionary_item(dictionary, key):\n",
    "    pp = pprint.PrettyPrinter(indent=1)\n",
    "    print(\"****** Printing Value with Key {0} from Dictionary *******\".format(key))\n",
    "    pp.pprint(dictionary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Printing Tests Value at Random *******\n",
      "{'headlines': ['5 Things More Businesses Should Care About',\n",
      "               'Watch This Ridiculously Adorable And Uplifting Video Of A Huge '\n",
      "               'Company Actually Doing Good Stuff',\n",
      "               '84 Seconds Of Proof That Some Companies Care About More Than '\n",
      "               'Just Their Bottom Line',\n",
      "               'Here Are 5 Core Beliefs I Wish More Companies Shared. And Then '\n",
      "               'Actually Acted On, Like This One.',\n",
      "               \"You Probably Haven't Heard Of Project Sunlight, But You Should \"\n",
      "               'Totally Agree With Its 5 Core Beliefs',\n",
      "               'This Huge Company Has 5 Goals For Its New Projectâ€¦ None Of '\n",
      "               'Which Involve Increasing Profits.',\n",
      "               \"What's Project Sunlight? A Beautiful Movement That's Already \"\n",
      "               'In Motion.'],\n",
      " 'id': '534c8ec3a649df271500005f',\n",
      " 'package_ids': ['20542', '87889', '89205', '91109', '91622', '92922', '93044']}\n",
      "\n",
      "\n",
      "****** Printing Packages Value at Random *******\n",
      "{'clicks': 34,\n",
      " 'created_at': '2013-06-12 02:51:58.69',\n",
      " 'excerpt': '',\n",
      " 'eyecatcher_id': '5332bbe31fae79f09f005b7f',\n",
      " 'first_place': True,\n",
      " 'headline': 'If You Had A Chance To Help A Blind Man Would You Do it Like '\n",
      "             'This?',\n",
      " 'impressions': 3609,\n",
      " 'lede': '<p>This blind man is looking for help on the street. &nbsp;A '\n",
      "         'stranger helps and what happens next will give you goosebumps.</p>',\n",
      " 'package_id': '45778',\n",
      " 'share_text': '',\n",
      " 'significance': 14.0,\n",
      " 'slug': 'if-you-had-a-chance-to-help-a-blind-man-would-you-do-it-like-this-4',\n",
      " 'square': 'Screen_Shot_2013-06-11_at_10.49.22_PM.png',\n",
      " 'test_id': '51b7e1c701d13641cd005d62',\n",
      " 'test_week': '201323',\n",
      " 'updated_at': '2016-04-02 16:26:48.847',\n",
      " 'winner': True}\n"
     ]
    }
   ],
   "source": [
    "print_random_dictionary_item(tests, \"Tests\")\n",
    "print(\"\\n\")\n",
    "print_random_dictionary_item(packages, \"Packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Read in a list of notable people\n",
    "For this example, we are interested in headlines that do or do not include notable people's names. We have compiled a list of notable people based on two datasources:\n",
    "1. The IMDB Top 100 most viewed actors in the years 2013-2015\n",
    "2. All people named in the Time 100 Most Influential People of the Year 2013-2015\n",
    "\n",
    "This list is stored in a file named `notable_people.csv`. It contains three columns:\n",
    "   * `person_name`: The person's full name OR their alias that they are better known by (e.g. 'Rihanna' will be present instead of 'Robyn Rihanna Fenty'). Note these are all lower case\n",
    "   * `rank`: If applicable, the rank on the Top 100 IMDB list that the actor occupied that year\n",
    "   * `year`: The year that they were featured on a Top 100 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            person_name  rank  year\n",
      "94       julianne hough    95  2013\n",
      "897      thomas piketty    -1  2015\n",
      "104  scarlett johansson     5  2014\n",
      "510         lee daniels    -1  2015\n",
      "346    steven spielberg    -1  2013 \n",
      "\n",
      "There are 900 rows in our dataframe.\n",
      "This corresponds to 467 notable people in all.\n"
     ]
    }
   ],
   "source": [
    "# read in the csv file and construct a pandas dataframe\n",
    "notable_people_df = pd.read_csv('notable_people.csv')\n",
    "\n",
    "# randomly print a sample of 5 people to see what the data looks like\n",
    "print(notable_people_df.sample(5),\"\\n\")\n",
    "\n",
    "# print the # of total rows\n",
    "print(\"There are {0} rows in our dataframe.\".format(len(notable_people_df)))\n",
    "\n",
    "# now see how many people this corresponds to (as there may be duplicates that are feature on multiple lists)\n",
    "print(\"This corresponds to {0} notable people in all.\".format(len(set(notable_people_df['person_name']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Calculate the valid comparisons with minimum and maximum effect sizes\n",
    "Now that we have a list of packages, and a list of notable people, it's time to compare the two! We specifically want to isolate tests where:\n",
    "1. At least one package has a headline with a notable person's name and one package does not\n",
    "2. The packages are identical except for the property you we are interested in. For example, we can only compare the headline of two packages if the image between the two is also the same.\n",
    "\n",
    "The below function `get_valid_tests` is intended to be flexible such that you can test any effect you wish. In this case, our `has_treatment` function is called `has_notable_person` and will return 1 if the headline has the name of a notable person and 0 otherwise. However, we could just as easily pass in the `has_number` function below and it will test for a different kind of treatment.\n",
    "\n",
    "Each test in the `valid_tests` dictionary tells us:\n",
    "* for the smallest possible effect size within that test, the package id of the package with the treatment we are testing for, and the package id of the package without the treatment we are testing for\n",
    "* for the largest possible effect size within that test, the package id of the package with the treatment we are testing for, and the package id of the package without the treatment we are testing for\n",
    "\n",
    "In our example, the smallest possible effect size will look for a package with a large clickthrough rate that does not have a notable person's name in it, and a package with a small clickthrough rate that does. These two packages must be a valid comparison (i.e. nothing other than the headline will be different). The largest possible effect size provides the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 valid tests that match the given criteria.\n"
     ]
    }
   ],
   "source": [
    "# One example of a 'has_treatment' function.\n",
    "# This function returns 1 if a headline contains the name of a notable person\n",
    "# and 0 otherwise.\n",
    "def has_notable_person(value):\n",
    "    \n",
    "    # clean headline if necessary for analysis\n",
    "    value = value.lower()\n",
    "    \n",
    "    # create list of notable people\n",
    "    # again, clean if necessary\n",
    "    list_of_notable_people = list(set(notable_people_df['person_name']))\n",
    "    \n",
    "    for notable_person in list_of_notable_people:\n",
    "        #if there is a notable person in the headline, return 1\n",
    "        if notable_person in value:\n",
    "            return 1\n",
    "    #if no notable person is found in the headline, return 0\n",
    "    return 0\n",
    "\n",
    "# here is another example of an effect you can test for\n",
    "# this returns 1 if a number is included in a property and 0 otherwise\n",
    "def has_number(value):\n",
    "    for character in value:\n",
    "        if character.isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# this function is what determines whether or not two packages are statistically\n",
    "# valid comparisons. For example, if one headline has an effect and the other does not,\n",
    "# the two packages may nonetheless be invalid comparisons if they have a different image \n",
    "def is_valid_comparison(package_id1, package_id2, properties_to_contrast):\n",
    "    \n",
    "    all_relevant_properties = ['headline', 'excerpt', 'lede', 'eyecatcher_id', 'square', 'share_text']\n",
    "        \n",
    "    properties_must_be_the_same = [x for x in all_relevant_properties if x not in properties_to_contrast]\n",
    "    \n",
    "    for prop in properties_must_be_the_same:\n",
    "        if packages[package_id1][prop] != packages[package_id2][prop]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# this function generates the tests that are directly comparable\n",
    "# the inputs to this function are:\n",
    "#   tests: dictionary of tests\n",
    "#   packages: dictionary of packages\n",
    "#   has_treatment: \n",
    "#      this is a function you define that should return 1 if an effect is present in a property and 0 otherwise\n",
    "#   is_valid_comparison:\n",
    "#      this defines which packages can be compared based on the list of properties specified. It is written for\n",
    "#      you above, though you may choose to alter it if you wish\n",
    "#   properties_to_contrast:\n",
    "#      this should be a list of columns you want to compare\n",
    "# in the example below, something will be considered a valid test if there is at least:\n",
    "#   one package with a headline and lede that contains at least one notable person's name\n",
    "#   one package with a headline and lede that do not contain at least one notable person's name\n",
    "valid_tests = up.get_valid_tests(tests, packages, \n",
    "                                 has_notable_person, \n",
    "                                 is_valid_comparison, \n",
    "                                 ['headline'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Printing Valid Tests Value at Random *******\n",
      "{'max': {'no_treatment': '92097', 'treatment': '88322'},\n",
      " 'min': {'no_treatment': '88419', 'treatment': '88924'}}\n"
     ]
    }
   ],
   "source": [
    "print_random_dictionary_item(valid_tests, \"Valid Tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Output valid test dictionary to CSV file\n",
    "Now that we have the results that are valid, we will output them to a format that we can then perform our analysis on.\n",
    "\n",
    "This section will generate three CSV files:\n",
    "1. \"max_effect_size_dataset.csv\"\n",
    "2. \"min_effect_size_dataset.csv\"\n",
    "3. \"headlines.csv\"\n",
    "\n",
    "Note you may want to alter this section if you plan to contrast another property, such as `lede` instead of `headline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headline_indexes(packages):\n",
    "    ## create headline idx\n",
    "    headline_idx = 0\n",
    "    headlines = {}\n",
    "    for p in packages:\n",
    "        headline = packages[p]['headline']\n",
    "        if headline not in headlines.keys():\n",
    "            headlines[headline] = headline_idx\n",
    "            headline_idx += 1 \n",
    "        packages[p]['headline_idx'] = headline_idx\n",
    "    return packages, headlines\n",
    "\n",
    "def write_dataset(packages, valid_tests):\n",
    "    \n",
    "    for effect_size in [\"max\", \"min\"]:\n",
    "        with open(\"upworthy_archive_exploratory_\" + effect_size + \"_effect_size_dataset.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"clickability_test_id\", \"headline_number\", \"has_treatment\",\"clicked\"])\n",
    "\n",
    "            for test in valid_tests.keys():\n",
    "                for condition in ['treatment', 'no_treatment']:\n",
    "                    clicks, impressions, headline_idx = up.get_properties(packages, \n",
    "                                                                          valid_tests[test][effect_size][condition])\n",
    "                    has_treatment = 1 if condition == 'treatment' else 0\n",
    "                    for i in range(0,impressions):\n",
    "                        clicked = 1 if i < clicks else 0\n",
    "                        writer.writerow([test, headline_idx, has_treatment, clicked]) \n",
    "                    \n",
    "def write_headline_index(headlines):\n",
    "    with open('headlines.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"headline_index\", \"headline\"])\n",
    "\n",
    "        for headline in headlines:\n",
    "            writer.writerow([headlines[headline], headline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages_with_headline_indexes, headlines = create_headline_indexes(packages)\n",
    "write_dataset(packages_with_headline_indexes, valid_tests)\n",
    "write_headline_index(headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voila! You are now free to go analyse the resulting datasets as you wish!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
